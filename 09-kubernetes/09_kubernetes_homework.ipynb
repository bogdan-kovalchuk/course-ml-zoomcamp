{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAzww_gMbzb9"
      },
      "source": [
        "# **Serverless homework**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SAwzT-RQswY"
      },
      "outputs": [],
      "source": [
        "!pip -q install onnx onnxruntime torchvision pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9EV-5-5bsiT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "\n",
        "from io import BytesIO\n",
        "from urllib import request\n",
        "from PIL import Image\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jnJ9_0zrIpW"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx.data\n",
        "!wget -q https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyPDumWOW0yi"
      },
      "source": [
        "### **<font color='red'>Question 1</font>**\n",
        "To be able to use this model, we need to know the name of the input and output nodes.\n",
        "\n",
        "What's the name of the output:\n",
        "- <font color='green'>output</font> ✅\n",
        "- sigmoid\n",
        "- softmax\n",
        "- prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-vO7_QoI9q6",
        "outputId": "d680d754-de4a-4ee9-ad8c-01be73506903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs:\n",
            "- input\n",
            "\n",
            "Outputs:\n",
            "- output\n"
          ]
        }
      ],
      "source": [
        "model = onnx.load(\"hair_classifier_v1.onnx\")\n",
        "graph = model.graph\n",
        "\n",
        "print(\"Inputs:\")\n",
        "for inp in graph.input:\n",
        "    print(\"-\", inp.name)\n",
        "\n",
        "print(\"\\nOutputs:\")\n",
        "for out in graph.output:\n",
        "  print(\"-\", out.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCsrOOLVa5zN"
      },
      "source": [
        "### **<font color='red'>Question 2</font>**\n",
        "Based on the previous homework, what should be the target size for the image?\n",
        "\n",
        "- 64x64\n",
        "- 128x128\n",
        "- <font color='green'>200x200</font> ✅\n",
        "- 256x256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SafsBK7c8y9"
      },
      "source": [
        "### **<font color='red'>Question 3</font>**\n",
        "Now we need to turn the image into numpy array and pre-process it.\n",
        "\n",
        "After the pre-processing, what's the value in the first pixel, the R channel?\n",
        "- -10.73\n",
        "- <font color='green'>-1.073</font> ✅\n",
        "- 1.073\n",
        "- 10.73"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMoXaJW4frwH"
      },
      "outputs": [],
      "source": [
        "def download_image(url):\n",
        "    with request.urlopen(url) as resp:\n",
        "        buffer = resp.read()\n",
        "    stream = BytesIO(buffer)\n",
        "    img = Image.open(stream)\n",
        "    return img\n",
        "\n",
        "\n",
        "def prepare_image(img, target_size):\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "    img = img.resize(target_size, Image.NEAREST)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH8w1nSscYIi",
        "outputId": "dd6c9f91-59d2-43c7-abb3-be1b217b1d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First R pixel: -1.073294\n"
          ]
        }
      ],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
        "\n",
        "img = download_image(url)\n",
        "img = prepare_image(img, (200, 200))\n",
        "tensor = train_transforms(img)\n",
        "array = tensor.numpy()\n",
        "print(\"First R pixel:\", array[0, 0, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJN-vaJYD4VX"
      },
      "source": [
        "### **<font color='red'>Question 4</font>**\n",
        "Now let's apply this model to this image. What's the output of the model?\n",
        "\n",
        "- <font color='green'>0.09</font> ✅\n",
        "- 0.49\n",
        "- 0.69\n",
        "- 0.89"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZCHyKGbEHsm",
        "outputId": "a05b8388-fe91-41c2-b4b4-aa639a869a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model output: 0.09\n"
          ]
        }
      ],
      "source": [
        "x = tensor.numpy()[None, :, :, :]\n",
        "\n",
        "session = ort.InferenceSession(\"hair_classifier_v1.onnx\")\n",
        "input_name = session.get_inputs()[0].name\n",
        "\n",
        "output = session.run(None, {input_name: x})[0]\n",
        "prediction = float(output[0][0])\n",
        "\n",
        "print(\"Model output:\", round(prediction, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zbiOmZildxB"
      },
      "source": [
        "### **<font color='red'>Question 5</font>**\n",
        "Download the base image agrigorev/model-2025-hairstyle:v1.\n",
        "\n",
        "So what's the size of this base image?\n",
        "\n",
        "- 88 Mb\n",
        "- 208 Mb\n",
        "- <font color='green'>608 Mb</font> ✅\n",
        "- 1208 Mb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFBYMa3f1sVy",
        "outputId": "1609ee4d-2036-4d66-bcb7-96303ef496c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v1: Pulling from agrigorev/model-2025-hairstyle\n",
            "\n",
            "\u001b[1B54c34aa3: Already exists \n",
            "\u001b[1B9533db7f: Already exists \n",
            "\u001b[1Bd8a1e1c2: Already exists \n",
            "\u001b[1Becca3b37: Already exists \n",
            "\u001b[1B94d707b7: Already exists \n",
            "\u001b[1B46295de2: Already exists \n",
            "\u001b[1Ba27bb275: Already exists \n",
            "\u001b[1BDigest: sha256:9e43d5a5323f7f07688c0765d3c0137af66d0154af37833ed721d6b4de6df528\n",
            "Status: Downloaded newer image for agrigorev/model-2025-hairstyle:v1\n",
            "docker.io/agrigorev/model-2025-hairstyle:v1\n",
            "REPOSITORY                       TAG       IMAGE ID       CREATED      SIZE\n",
            "agrigorev/model-2025-hairstyle   v1        4528ad1525d5   4 days ago   608MB\n"
          ]
        }
      ],
      "source": [
        "!docker pull agrigorev/model-2025-hairstyle:v1\n",
        "!docker images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClvjSEp7mdh9"
      },
      "source": [
        "### **<font color='red'>Question 6</font>**\n",
        "Now let's extend this docker image, install all the required libraries and add the code for lambda.\n",
        "\n",
        "You don't need to include the model in the image. It's already included. The name of the file with the model is hair_classifier_empty.onnx and it's in the current workdir in the image (see the Dockerfile above for the reference). The provided model requires the same preprocessing for images regarding target size and rescaling the value range than used in homework 8.\n",
        "\n",
        "Now run the container locally.\n",
        "\n",
        "Score this image: https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\n",
        "\n",
        "What's the output from the model?\n",
        "\n",
        "- -1.0\n",
        "- <font color='green'>-0.10</font> ✅\n",
        "- 0.10\n",
        "- 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ9umkBO1uTH"
      },
      "outputs": [],
      "source": [
        "# docker build -t hairstyle-lambda .\n",
        "# docker run -p 8080:8080 hairstyle-lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7GS3D7P3eJ4",
        "outputId": "c6a77983-698d-4e00-d30f-617951ca29b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"statusCode\": 200, \"body\": \"{\\\"prediction\\\": -0.10220836102962494, \\\"rounded\\\": -0.1}\"}"
          ]
        }
      ],
      "source": [
        "!curl -X POST \\\n",
        "  \"http://localhost:8080/2015-03-31/functions/function/invocations\" \\\n",
        "  -d '{\"url\": \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"}'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}