{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb7e6a4-6250-44b9-a67f-1c6db603d2f7",
   "metadata": {},
   "source": [
    "# **Deployment homework**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d04f86-2a2f-4684-a709-65a2e22dd7e2",
   "metadata": {},
   "source": [
    "We recommend using python 3.12 or 3.13 in this homework.\n",
    "\n",
    "In this homework, we're going to continue working with the lead scoring dataset. You don't need the dataset: we will provide the model for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c3f9b2-735b-4681-a57f-d3f019254de3",
   "metadata": {},
   "source": [
    "### **<font color='red'>Question 1</font>**\n",
    "- Install `uv`\n",
    "- What's the version of uv you installed?\n",
    "- Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04241406-d8f0-4056-acdc-3660d0f80401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uv 0.9.5\n"
     ]
    }
   ],
   "source": [
    "!uv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7822b1fd-941a-4ebb-b41e-f996a66595a6",
   "metadata": {},
   "source": [
    "### Initialize an empty uv project\n",
    "You should create an empty folder for homework and do it there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67af458-1aa5-43e0-aad0-c0f0cfbc2074",
   "metadata": {},
   "source": [
    "### **<font color='red'>Question 2</font>**\n",
    "- Use `uv` to install Scikit-Learn version 1.6.1\n",
    "- What's the first hash for Scikit-Learn you get in the lock file?\n",
    "- Include the entire string starting with sha256:, don't include quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e61e27-b8d6-4897-a1e4-c900b818d81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:b4fc2525eca2c69a59260f583c56a7557c6ccdf8deafdba6e060f94c1c59738e\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(\"uv.lock\", \"r\", encoding=\"utf-8\") as f:\n",
    "    inside = False\n",
    "    for line in f:\n",
    "        if line == 'name = \"scikit-learn\"\\n':\n",
    "            inside = True\n",
    "            continue\n",
    "        if inside:\n",
    "            match = re.search(r\"sha256:([a-f0-9]+)\", line)\n",
    "            if match:\n",
    "                print(\"sha256:\" + match.group(1))\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544ce44-154a-427a-8078-64da900482fb",
   "metadata": {},
   "source": [
    "### Models\n",
    "We have prepared a pipeline with a dictionary vectorizer and a model.\n",
    "\n",
    "It was trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "categorical = ['lead_source']\n",
    "numeric = ['number_of_courses_viewed', 'annual_income']\n",
    "\n",
    "df[categorical] = df[categorical].fillna('NA')\n",
    "df[numeric] = df[numeric].fillna(0)\n",
    "\n",
    "train_dict = df[categorical + numeric].to_dict(orient='records')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "pipeline.fit(train_dict, y_train)\n",
    "```\n",
    "\n",
    "> **Note:** You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "The trained pipeline was saved with **Pickle**.  \n",
    "You can download it using the following command:\n",
    "\n",
    "```bash\n",
    "wget https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419917ce-15ab-42c6-a7cf-feedb8c6c609",
   "metadata": {},
   "source": [
    "### **<font color='red'>Question 3</font>**\n",
    "Let's use the model!\n",
    "\n",
    "Write a script for loading the pipeline with pickle  \n",
    "Score this record:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"lead_source\": \"paid_ads\",\n",
    "    \"number_of_courses_viewed\": 2,\n",
    "    \"annual_income\": 79276.0\n",
    "}\n",
    "```\n",
    "\n",
    "What's the probability that this lead will convert?\n",
    "\n",
    "- 0.333  \n",
    "- <font color='green'>0.533</font> ✅\n",
    "- 0.733  \n",
    "- 0.933  \n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```\n",
    "$ md5sum pipeline_v1.bin\n",
    "7d17d2e4dfbaf1e408e1a62e6e880d49 *pipeline_v1.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c25be3-e4c4-4ca9-8f6e-0a2b7c6aee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-24 10:38:21--  https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
      "Resolving github.com (github.com)... 140.82.121.3, 64:ff9b::8c52:7903\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin [following]\n",
      "--2025-10-24 10:38:22--  https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1300 (1.3K) [application/octet-stream]\n",
      "Saving to: ‘pipeline_v1.bin’\n",
      "\n",
      "pipeline_v1.bin     100%[===================>]   1.27K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-10-24 10:38:23 (63.5 MB/s) - ‘pipeline_v1.bin’ saved [1300/1300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O pipeline_v1.bin https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de50a591-5886-4800-a50a-ac740a7e6ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(), LogisticRegression(solver='liblinear'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model_file = 'pipeline_v1.bin'\n",
    "with open(model_file, 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)\n",
    " \n",
    "dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7399436d-25a3-48fd-8314-37d34735164d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.534)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead = {\n",
    "    \"lead_source\": \"paid_ads\",\n",
    "    \"number_of_courses_viewed\": 2,\n",
    "    \"annual_income\": 79276.0\n",
    "}\n",
    "X = dv.transform([lead])\n",
    "model.predict_proba(X)[0,1].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47790c24-3c93-4b80-b1de-6b81655bc21d",
   "metadata": {},
   "source": [
    "### **<font color='red'>Question 4</font>**\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "- Install FastAPI\n",
    "- Write FastAPI code for serving the model\n",
    "- Now score this client using requests:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0\n",
    "}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "What's the probability that this client will get a subscription?\n",
    "- 0.334\n",
    "- 0.534\n",
    "- 0.734\n",
    "- 0.934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef1295-4ede-47a9-9230-d020ceb20006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f2d34f1-9ba7-4eb9-b03a-5a3047b03768",
   "metadata": {},
   "source": [
    "### Docker\n",
    "Install Docker. We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `agrigorev/zoomcamp-model:2025`. You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `3.13.5-slim-bookworm` and has a pipeline with logistic regression (a different one) as well a dictionary vectorizer inside.\n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```\n",
    "FROM python:3.13.5-slim-bookworm\n",
    "WORKDIR /code\n",
    "COPY pipeline_v2.bin .\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to: `agrigorev/zoomcamp-model:2025`.\n",
    "\n",
    "> Note: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026b7c4-dae7-49f0-a0d7-f04f97e47c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
